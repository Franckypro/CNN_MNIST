# CNN_MNIST

# Classification d'images avec un CNN üñºÔ∏èü§ñ

Ce projet utilise un **r√©seau de neurones convolutifs (CNN)** pour la classification d'images du dataset **MNIST**. Ce README d√©taille les √©tapes n√©cessaires pour ex√©cuter ce projet, de la pr√©paration de l'environnement √† la pr√©diction des nouvelles images.

## 1Ô∏è‚É£ Pr√©paration de l‚Äôenvironnement üöÄ

### Installation des biblioth√®ques n√©cessaires üì¶

Installez les biblioth√®ques suivantes en ex√©cutant les commandes :

```bash
pip install tensorflow
pip install matplotlib
pip install numpy
```

### Importation des biblioth√®ques üìö

```python
import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import random
```

## 2Ô∏è‚É£ Chargement et exploration du dataset üìä

### Chargement des donn√©es MNIST

```python
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()
```

- Les images sont normalis√©es pour faciliter l'apprentissage.
- Une dimension est ajout√©e pour correspondre aux entr√©es du CNN.

### Visualisation des donn√©es augment√©es

```python
train_datagen = ImageDataGenerator(
    rotation_range=20, width_shift_range=0.2, height_shift_range=0.2,
    shear_range=0.2, zoom_range=0.2, horizontal_flip=False, fill_mode='nearest'
)

fig, axes = plt.subplots(1, 5, figsize=(10, 2))
for i in range(5):
    augmented_image = train_datagen.random_transform(x_train[i])
    axes[i].imshow(augmented_image.squeeze(), cmap='gray')
    axes[i].axis('off')
plt.show()
```

## 3Ô∏è‚É£ Cr√©ation du mod√®le CNN üß†

Le mod√®le CNN est compos√© de deux couches de convolution et de max-pooling pour extraire les caract√©ristiques des images, puis de couches denses pour effectuer la classification.

```python
classifier = Sequential([
    Conv2D(32, (3, 3), input_shape=(28, 28, 1), activation="relu"),
    MaxPooling2D(pool_size=(2, 2)),
    Conv2D(64, (3, 3), activation="relu"),
    MaxPooling2D(pool_size=(2, 2)),
    Flatten(),
    Dense(units=128, activation="relu"),
    Dense(units=10, activation="softmax")
])
```

## 4Ô∏è‚É£ Compilation et entra√Ænement ‚ö°

Le mod√®le est compil√© avec l'optimiseur `adam` et la fonction de perte `sparse_categorical_crossentropy`.

```python
classifier.compile(optimizer="adam", loss="sparse_categorical_crossentropy", metrics=['accuracy'])
history = classifier.fit(
    train_datagen.flow(x_train, y_train, batch_size=32),
    validation_data=(x_test, y_test),
    epochs=5
)
```

## 5Ô∏è‚É£ √âvaluation du mod√®le üìà

### Tracer les courbes de pr√©cision et de perte

```python
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Pr√©cision entra√Ænement')
plt.plot(history.history['val_accuracy'], label='Pr√©cision validation')
plt.xlabel('√âpoques')
plt.ylabel('Pr√©cision')
plt.legend()
plt.title('√âvolution de la pr√©cision')

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Perte entra√Ænement')
plt.plot(history.history['val_loss'], label='Perte validation')
plt.xlabel('√âpoques')
plt.ylabel('Perte')
plt.legend()
plt.title('√âvolution de la perte')

plt.show()
```

### Pr√©cision sur le test set üéØ

```python
test_loss, test_acc = classifier.evaluate(x_test, y_test, verbose=2)
print(f"\nPr√©cision sur le test set : {test_acc * 100:.2f}%")
```

## 6Ô∏è‚É£ Pr√©diction sur de nouvelles images üîÆ

S√©lectionnez une image au hasard, effectuez la pr√©diction et comparez-la √† la vraie √©tiquette.

```python
index = random.randint(0, len(x_test))  
test_image = x_test[index]

plt.imshow(test_image.squeeze(), cmap='gray')
plt.axis('off')
plt.title("Image test")
plt.show()

test_image = np.expand_dims(test_image, axis=0)
prediction = classifier.predict(test_image)
predicted_label = np.argmax(prediction)

print(f"Pr√©diction du mod√®le : {predicted_label}")
print(f"Vraie √©tiquette : {y_test[index]}")
```

Si la pr√©diction est correcte, un emoji ‚úÖ sera affich√©, sinon un emoji ‚ùå sera affich√©.

## Bonus : Am√©liorations possibles üéÅ

Vous pouvez utiliser un mod√®le pr√©-entra√Æn√© tel que **MobileNetV2** pour am√©liorer les performances du mod√®le.

### Chargement et transformation des donn√©es

Les images sont redimensionn√©es √† `224x224` pour √™tre compatibles avec MobileNetV2, et des transformations sont appliqu√©es.

```python
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
from tensorflow.keras.preprocessing.image import ImageDataGenerator

x_train = np.repeat(x_train, 3, axis=-1)
x_test = np.repeat(x_test, 3, axis=-1)
```

### Construction du mod√®le avec MobileNetV2

```python
base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights="imagenet")
base_model.trainable = False

model = Sequential([
    tf.keras.layers.Resizing(224, 224),
    base_model,
    Flatten(),
    Dense(128, activation="relu"),
    Dropout(0.5),
    Dense(10, activation="softmax")
])
```

### Entra√Ænement avec Data Augmentation

```python
history = model.fit(training_set, validation_data=testing_set, epochs=5)
```

### Visualisation des performances

```python
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Pr√©cision entra√Ænement')
plt.plot(history.history['val_accuracy'], label='Pr√©cision validation')
plt.xlabel('√âpoques')
plt.ylabel('Pr√©cision')
plt.legend()
plt.title('√âvolution de la pr√©cision')

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Perte entra√Ænement')
plt.plot(history.history['val_loss'], label='Perte validation')
plt.xlabel('√âpoques')
plt.ylabel('Perte')
plt.legend()
plt.title('√âvolution de la perte')

plt.show()
```

### Test sur une image al√©atoire

```python
idx = random.randint(0, len(x_test) - 1)
test_image = x_test[idx]
test_image_resized = tf.image.resize(test_image, (224, 224))
test_image_resized = np.expand_dims(test_image_resized, axis=0)

prediction = model.predict(test_image_resized)
predicted_label = np.argmax(prediction)

plt.imshow(test_image.squeeze(), cmap='gray')
plt.axis('off')
plt.title(f"Pr√©diction du mod√®le: {predicted_label}")
plt.show()
```

## Conclusion üéâ

Ce mod√®le atteint une pr√©cision de **98.47%** sur le test set avec le CNN classique et **56.55%** avec le mod√®le pr√©-entra√Æn√© MobileNetV2. Vous pouvez am√©liorer encore ce mod√®le en ajustant les hyperparam√®tres ou en fine-tunant les couches du mod√®le pr√©-entra√Æn√©.

Merci d'avoir consult√© ce projet ! üòÉ
```

N'h√©sitez pas √† me faire savoir si vous avez besoin d'autres d√©tails ou modifications. üòä
```
‚úçÔ∏è Auteur
Fouejio Francky Jo√´l
